{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd01584-8a4a-4935-8374-7220b37c1d46",
   "metadata": {},
   "source": [
    "### NoTE For Next Time I resume Project\n",
    "* Format The functions well\n",
    "* Document the results\n",
    "* Save the pickle files inside the function\n",
    "* Create Scripts\n",
    "* Don't start streamlit until after payment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f092cd-4a02-453e-bbde-57b772bf0089",
   "metadata": {},
   "source": [
    "* Data Name : Wili 2018\n",
    "* Source: Kaggle [https://www.kaggle.com/datasets/sharansmenon/wili-2018?select=data.csv]\n",
    "* The main language data. Contains about 200k instances for 235 languages\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bc88cd98-5e43-4755-865c-15c62ed23341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3821245-9fae-4528-99f0-bf98e314462c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd0f1d87-f43a-46a1-80c4-52ac7de005cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e375d41b-f540-4367-b352-8772670f3dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Klement Gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>est\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sebes, Joseph; Pereira Thomas (1961) (på eng)....</td>\n",
       "      <td>swe\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...</td>\n",
       "      <td>mai\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Après lo cort periòde d'establiment a Basilèa,...</td>\n",
       "      <td>oci\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...</td>\n",
       "      <td>tha\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  Klement Gottwaldi surnukeha palsameeriti ning ...  est\\n\n",
       "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....  swe\\n\n",
       "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...  mai\\n\n",
       "3  Après lo cort periòde d'establiment a Basilèa,...  oci\\n\n",
       "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...  tha\\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f4d89-7a05-424f-97ab-b30ba15fa3f0",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "* Remove Excape strings at the end of the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d2abd85-b55d-4d47-a2d4-dac06fdc8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters: dataframe(pd.DataFrame): Main Downloaded Data\n",
    "\n",
    "    Return: pd.DataFrame (A Clean Version of Data Frame)\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe['class'] = dataframe['class'].apply(lambda x: x[:-1])\n",
    "\n",
    "    print('Cleaning Completeed')\n",
    "    return(dataframe)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7efcac6b-1776-4d7a-95b6-c26e16c52af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1816eebc-f58e-4636-9d4b-6d1f105dd68d",
   "metadata": {},
   "source": [
    "## Data PreProcesing\n",
    "* Select only data label to Afrikaans, Spanish and German only\n",
    "* Feature Extraction (TF-IDF- Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5a45e79-709f-4ec1-8bb8-050e5975f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_selected_language(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters: dataframe(pd.DataFrame) -> Main Data Frame containing all Data \n",
    "\n",
    "    Returns: pd.DataFrame -> A Dataframe containing only Afrikaans, Spanish, German, Alemannic German\n",
    "\n",
    "    \"\"\"\n",
    "    extracted_data = dataframe[(dataframe['class'] == 'afr') | (dataframe['class'] == 'spa') | (dataframe['class'] == 'als') | (dataframe['class'] == 'deu')]\n",
    "    print('Succesfully Extracted Data')\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def save_extracted_data_to_csv(dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Parameters: dataframe(pd.DataFrame) -> Dataframe of already extracted languages\n",
    "\n",
    "    Save The Data to a csv file\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe.to_csv('data_folder/extracted_data.csv', index=False)\n",
    "    print('Succesfully Saved To Csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf4eac-f8e9-41b9-a002-e780d409cf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1dd5c3d3-1db9-4663-853f-508de614ff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully Extracted Data\n",
      "Succesfully Saved To Csv\n"
     ]
    }
   ],
   "source": [
    "save_extracted_data_to_csv(extract_selected_language(main_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "534c7697-12a7-4baa-912c-e937bab36a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uf di hitig Greßi isch s schließlig anne 1998 ...</td>\n",
       "      <td>als</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En Navidad de 1974, poco después de que interp...</td>\n",
       "      <td>spa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499: D Schlacht im Schwaderloh im Thurgau goh...</td>\n",
       "      <td>als</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die geelblom (Cineraria saxifraga) is 'n klein...</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Talle van mense, dikwels uit geïsoleerde gemee...</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class\n",
       "0  Uf di hitig Greßi isch s schließlig anne 1998 ...   als\n",
       "1  En Navidad de 1974, poco después de que interp...   spa\n",
       "2  1499: D Schlacht im Schwaderloh im Thurgau goh...   als\n",
       "3  Die geelblom (Cineraria saxifraga) is 'n klein...   afr\n",
       "4  Talle van mense, dikwels uit geïsoleerde gemee...   afr"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data = pd.read_csv('data_folder/extracted_data.csv')\n",
    "extracted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf22fb05-9caa-402e-8358-91de680138df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_et_label_encoding(dataframe: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Parameters:  dataframe: pd.DataFrame -> Data frame of selected language\n",
    "\n",
    "    Return: A list [text_vectors, language_label, language_label_mapping]\n",
    "\n",
    "    Receive a Dataframe and perform the following operations\n",
    "    * Split to Features and Labels\n",
    "    * Perform Labeel Encoding on the Label Section\n",
    "    * Perform Feature Extarction usinf TfIDF on the feature Section\n",
    "    * Extract Label Mapping\n",
    "    * Return A list Containing The Vectors, Labels and Label Mapping\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Split Data to Texts and Labels\n",
    "    texts = dataframe.text\n",
    "    language_label = dataframe['class']\n",
    "    \n",
    "    #Encoding\n",
    "    label_encoder = LabelEncoder() # initialize Encoder\n",
    "    language_label= label_encoder.fit_transform(language_label)\n",
    "    language_label_mapping = dict(zip(label_encoder.classes_,\n",
    "                                     label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "    # Save Encoding Dictionary\n",
    "    with open('pickles/language_label_mapping.pkl','wb') as file0:\n",
    "        pickle.dump(language_label_mapping, file0)\n",
    "    \n",
    "    #Vectorization\n",
    "    tfidf_vectorizer = TfidfVectorizer() # Initialize the Vectorizer\n",
    "\n",
    "    tfidf_text_vectors = tfidf_vectorizer.fit_transform(texts).toarray()\n",
    "    \n",
    "    # Save Vectorizer\n",
    "    with open('pickles/tfidf_vectorizer.pkl','wb') as file:\n",
    "        pickle.dump(tfidf_vectorizer, file)\n",
    "    \n",
    "    print('Encoding And Preprocessing Completed')\n",
    "    return [tfidf_text_vectors,language_label,language_label_mapping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bba79929-0d2d-42b3-acef-37a53398c5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding And Preprocessing Completed\n"
     ]
    }
   ],
   "source": [
    "vectors, label, mapping = feature_extraction_et_label_encoding(extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9041d59-c7e3-430a-bfbc-8bcec1f7e15f",
   "metadata": {},
   "source": [
    "### Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4abd5c96-0c16-42b5-8400-13f471a45927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(vectors: pd.Series, label: pd.Series) -> tuple:\n",
    "    \"\"\"\n",
    "    Parameters vectors(pd.Series) label(pd.Series)\n",
    "\n",
    "    Return: A tupple of the split features\n",
    "\n",
    "    Split Data into Train and test features with 30 Percent to test and 70 to training\n",
    "    \n",
    "    \"\"\"\n",
    "    train_features, test_features, train_label, test_label = train_test_split(vectors,\n",
    "                                                                              label,\n",
    "                                                                              test_size=0.30, \n",
    "                                                                              random_state=3)\n",
    "    return train_features,test_features,train_label,test_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38cda91d-8f13-4e72-a266-03f7c6be588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train_features: pd.Series,\n",
    "                 test_features: pd.Series,\n",
    "                 train_label: pd.Series,\n",
    "                 test_label: pd.Series):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters : \n",
    "    train_features -> features to be use in training (pd.Series)\n",
    "    test_features -> features for training (pd.Series)\n",
    "    train_labels -> training labels (pd.Series)\n",
    "    test_labels -> testing labels (pd.Series)\n",
    "    Return A tupple for the prediction of all Models\n",
    "\n",
    "    Train 3 Language Identification Models\n",
    "    \n",
    "    \"\"\"\n",
    "    #Models Initialization\n",
    "    naive_bayes_model = MultinomialNB() # Naive Bayes\n",
    "    logistic_regression_model = LogisticRegression() # Logistic Regression\n",
    "    random_forest_classifier_model = RandomForestClassifier() # Random Forest Classifier\n",
    "    print('Models Initialization Completed')\n",
    "    \n",
    "\n",
    "    #Models Training\n",
    "    naive_bayes_model.fit(train_features, train_label)\n",
    "    logistic_regression_model.fit(train_features, train_label)\n",
    "    random_forest_classifier_model.fit(train_features, train_label)\n",
    "    print('Models Training Completed')\n",
    "\n",
    "    #Models Predictions\n",
    "    naive_bayes_model_prediction = naive_bayes_model.predict(test_features)\n",
    "    logistic_regression_model_prediction = logistic_regression_model.predict(test_features)\n",
    "    random_forest_classifier_model_prediction = random_forest_classifier_model.predict(test_features)\n",
    "\n",
    "\n",
    "    return naive_bayes_model_prediction, logistic_regression_model_prediction, random_forest_classifier_model_prediction\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b5940bb-f73a-4b89-a870-6d7788d81d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_models(test_label: pd.Series, \n",
    "                    naive_bayes_prediction: pd.Series, \n",
    "                    logistic_regression_prediction: pd.Series, \n",
    "                    random_forest_prediction: pd.Series):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - test_label: True labels for the test set (pd.Series)\n",
    "    - naive_bayes_prediction: Predictions from the Naive Bayes model (pd.Series)\n",
    "    - logistic_regression_prediction: Predictions from the Logistic Regression model (pd.Series)\n",
    "    - random_forest_prediction: Predictions from the Random Forest model (pd.Series)\n",
    "    \n",
    "    Return:\n",
    "    - Prints evaluation metrics including F1-score, Recall, Precision, and Classification Report for all models.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Model Evaluation: Naive Bayes\n",
    "    print('Naive Bayes Model Evaluation:')\n",
    "    print(f'F1-Score: {f1_score(test_label, naive_bayes_prediction, average=\"weighted\"):.4f}')\n",
    "    print(f'Recall: {recall_score(test_label, naive_bayes_prediction, average=\"weighted\"):.4f}')\n",
    "    print(f'Precision: {precision_score(test_label, naive_bayes_prediction, average=\"weighted\"):.4f}')\n",
    "    print('Classification Report:\\n', classification_report(test_label, naive_bayes_prediction))\n",
    "    \n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Model Evaluation: Logistic Regression\n",
    "    print('Logistic Regression Model Evaluation:')\n",
    "    print(f'F1-Score: {f1_score(test_label, logistic_regression_prediction, average=\"weighted\"):.4f}')\n",
    "    print(f'Recall: {recall_score(test_label, logistic_regression_prediction, average=\"weighted\"):.4f}')\n",
    "    print(f'Precision: {precision_score(test_label, logistic_regression_prediction, average=\"weighted\"):.4f}')\n",
    "    print('Classification Report:\\n', classification_report(test_label, logistic_regression_prediction))\n",
    "    \n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Model Evaluation: Random Forest\n",
    "    print('Random Forest Model Evaluation:')\n",
    "    print(f'F1-Score: {f1_score(test_label, random_forest_prediction, average=\"weighted\"):.4f}')\n",
    "    print(f'Recall: {recall_score(test_label, random_forest_prediction, average=\"weighted\"):.4f}')\n",
    "    print(f'Precision: {precision_score(test_label, random_forest_prediction, average=\"weighted\"):.4f}')\n",
    "    print('Classification Report:\\n', classification_report(test_label, random_forest_prediction))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dce99d57-6788-4c4c-9459-044cadf37414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Initialization Completed\n",
      "Models Training Completed\n",
      "Naive Bayes Model Evaluation:\n",
      "F1-Score: 0.9883\n",
      "Recall: 0.9883\n",
      "Precision: 0.9888\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       309\n",
      "           1       1.00      0.96      0.98       297\n",
      "           2       0.96      1.00      0.98       285\n",
      "           3       1.00      0.99      1.00       309\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.99      0.99      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n",
      "--------------------------------------------------\n",
      "Logistic Regression Model Evaluation:\n",
      "F1-Score: 0.9842\n",
      "Recall: 0.9842\n",
      "Precision: 0.9843\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       309\n",
      "           1       0.98      0.97      0.97       297\n",
      "           2       0.96      0.99      0.97       285\n",
      "           3       0.99      0.99      0.99       309\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.98      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "--------------------------------------------------\n",
      "Random Forest Model Evaluation:\n",
      "F1-Score: 0.9875\n",
      "Recall: 0.9875\n",
      "Precision: 0.9879\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       309\n",
      "           1       0.99      0.96      0.98       297\n",
      "           2       0.96      1.00      0.98       285\n",
      "           3       1.00      0.99      1.00       309\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.99      0.99      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_label, test_label = split_data(vectors,label)\n",
    "\n",
    "naive_bayes_pred, logistic_regression_pred, random_forest_pred = train_models(train_features, test_features, train_label, test_label)\n",
    "\n",
    "# Call evaluate function\n",
    "evaluate_models(test_label, naive_bayes_pred, logistic_regression_pred, random_forest_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e7b6382-6b0f-44ac-bd9a-2a4d9b876b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_tuning(train_features: pd.Series,\n",
    "                       test_features: pd.Series,\n",
    "                       train_label: pd.Series,\n",
    "                       test_label: pd.Series):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for Naive Bayes, Logistic Regression, and Random Forest models using GridSearchCV.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_features: Training features (pd.Series)\n",
    "    - train_label: Training labels (pd.Series)\n",
    "    \n",
    "    Returns:\n",
    "    - Best hyperparameters for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Naive Bayes Hyperparameter Tuning\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes_params = {\n",
    "        'alpha': [0.1, 0.5, 1.0]  # Example hyperparameter values for Naive Bayes\n",
    "    }\n",
    "    print('Starting HyperParameter Tuning')\n",
    "    naive_bayes_grid = GridSearchCV(estimator=naive_bayes, param_grid=naive_bayes_params, cv=5, scoring='f1_weighted')\n",
    "    naive_bayes_grid.fit(train_features, train_label)\n",
    "    naive_bayes_grid_predictions = naive_bayes_grid.predict(test_features)\n",
    "    print(f'Best Params for Naive Bayes: {naive_bayes_grid.best_params_}')\n",
    "\n",
    "    print('Naive Bayes Model Grid Search Evaluation:')\n",
    "    print(f'F1-Score: {f1_score(test_label, naive_bayes_grid_predictions, average=\"weighted\"):.4f}')\n",
    "    print(f'Recall: {recall_score(test_label, naive_bayes_grid_predictions, average=\"weighted\"):.4f}')\n",
    "    print(f'Precision: {precision_score(test_label, naive_bayes_grid_predictions, average=\"weighted\"):.4f}')\n",
    "    print('Classification Report:\\n', classification_report(test_label, naive_bayes_grid_predictions))\n",
    "    \n",
    "    \n",
    "   \n",
    "    return naive_bayes_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "60331174-3c66-40d7-a080-077d004e7da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HyperParameter Tuning\n",
      "Best Params for Naive Bayes: {'alpha': 0.1}\n",
      "Naive Bayes Model Grid Search Evaluation:\n",
      "F1-Score: 0.9933\n",
      "Recall: 0.9933\n",
      "Precision: 0.9935\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       309\n",
      "           1       1.00      0.98      0.99       297\n",
      "           2       0.98      1.00      0.99       285\n",
      "           3       1.00      1.00      1.00       309\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.99      0.99      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naivebayes = grid_search_tuning(train_features, test_features, train_label, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e04c5504-7578-4b82-a995-3bdc80e5e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/final_naivebaye_model.pkl','wb') as file:\n",
    "    pickle.dump(naivebayes, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534434c-a74b-4ea9-994e-b81361eae0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
